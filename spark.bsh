##############
# NOT TESTED #
##############

# set up spark (this should be already here)
## download
wget http://d3kbcqa49mib13.cloudfront.net/spark-1.2.0-bin-hadoop2.4.tgz
## extract
tar -xvf spark-1.2.0-bin-hadoop2.4.tgz
## remove the archive
rm spark-1.2.0-bin-hadoop2.4.tgz
## move to etc
sudo mv spark-1.2.0-bin-hadoop2.4 /etc/spark
## set SPARK_HOME
echo 'SPARK_HOME=/etc/spark' | sudo tee --append /etc/environment

# TODO get name node form ambari
$namenode=""

# set up the configuration (assumption is that the NN is in $namenode)
## copy the templates
sudo cp /etc/spark/conf/spark-defaults.conf.template /etc/spark/conf/spark-defaults.conf
sudo cp /etc/spark/conf/spark-env.sh.template /etc/spark/conf/spark-env.sh
## enable logging
echo 'spark.eventLog.enabled           true' | sudo tee --append /etc/spark/conf/spark-defaults.conf
## set the logging folder
echo 'spark.eventLog.dir               hdfs://$namenode:8020/user/ubuntu/spark-app-logs' | sudo tee --append /etc/spark/conf/spark-defaults.conf
## set some JVM options
echo 'spark.driver.extraJavaOptions -Dhdp.version=2.2.0.0-2041' | sudo tee --append /etc/spark/conf/spark-defaults.conf
echo 'spark.yarn.am.extraJavaOptions -Dhdp.version=2.2.0.0-2041'  | sudo tee --append /etc/spark/conf/spark-defaults.conf

## set the Web server port
echo 'SPARK_MASTER_WEBUI_PORT=8888'  | sudo tee --append /etc/spark/conf/spark-env.sh

#copy the yarn configuration (assumption is that there is at least one slave)
sudo mkdir /hadoop
sudo scp -r slave1:/etc/hadoop/conf /hadoop 

#set YARN_CONF_DIR env variable
echo 'YARN_CONF_DIR=/hadoop/conf' | sudo tee --append /etc/environment

#change ownership (just in case) (should already be here)
sudo chown -R ubuntu /etc/spark
sudo chmod -R +x /etc/spark/sbin 
sudo chmod -R +x /etc/spark/bin

#push the configuration to all the slaves
ansible cumpa -m copy -a "src=/etc/spark dest=/etc" --sudo
ansible cumpa -a "chown -R ubuntu /etc/spark " --sudo
ansible cumpa -a "chmod -R +x /etc/spark/bin" --sudo
ansible cumpa -a "chmod -R +x /etc/spark/sbin" --sudo

#create home folder (assumption, there exists at least 1 slave)
ansible slave1 -a "sudo -u hdfs hdfs dfs -mkdir /user/ubuntu"
ansible slave1 -a "sudo -u hdfs hdfs dfs -chown ubuntu /user/ubuntu"

#add the slaves to the spark configuration
cat /etc/hosts | grep slave | grep -v \#  | cut -d " " -f3 > $SPARK_HOME/conf/slaves

#start the master and the slaves
$SPARK_HOME/sbin/start-all.sh

#start the jobserver (assumes that the spark job server is already in the image)
/home/ubuntu/job-server/server_start.sh
